model:
  model_name: google/flan-t5-large
  load_in_8bit: true
optimizer:
  lr: 0.001
datamodule:
  dataset_name: zero_shot
  batch_size: 16
  num_workers: 8
  max_context_length: 1024
  max_target_length: 256
trainer:
  max_epochs: 10
  accelerator: gpu
  accumulate_grad_batches: 1
  precision: 'bf16'
  limit_val_batches: 64
generation:
  temperature: 1.0
metrics:
  - anls
  - extraction_match

peft_config_type: lora
lora:
  r: 16
  lora_alpha: 32
  lora_dropout: 0.05
  bias: none
